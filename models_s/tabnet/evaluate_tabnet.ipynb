{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0faae6-a88c-4289-aece-2185fa5f6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tab_model import TabNetRegressor, TabModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66897513-7167-43c3-890b-5296525cd9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_datapaths(\n",
    "    train_idx,\n",
    "    val_idx,\n",
    "    files='sunny', \n",
    "    target_cols=[\"ccn_001\", \"ccn_003\", \"ccn_006\"],\n",
    "    exclude_cols = [\"XLONG\", \"XLAT\"],\n",
    "):\n",
    "    # getting colname\n",
    "    featloc = \"/home/kphadke/hackathon/norm_data_timesteps_feat\"\n",
    "    targloc = \"/home/kphadke/hackathon/norm_data_timesteps_targ\"\n",
    "\n",
    "    featcols = np.load(f\"{featloc}/x_name.npy\")\n",
    "    targcols = np.load(f\"{targloc}/y_name.npy\")\n",
    "    \n",
    "    target_idx = [np.where(targcols == i)[0].item() for i in target_cols ]\n",
    "    feat_idx   = [np.where(featcols == i)[0].item() for i in featcols if i not in exclude_cols]\n",
    "    \n",
    "    # getting paths\n",
    "    if files == 'sunny':\n",
    "        # my data\n",
    "        featloc = \"/home/kwoksun2/hackathon_data/norm_data\"\n",
    "        targloc = \"/home/kwoksun2/hackathon_data/norm_data\"\n",
    "\n",
    "        train_feat_files = [f\"{featloc}/t{t}_feat.npy\" for t in train_idx]\n",
    "        val_feat_files   = [f\"{featloc}/t{t}_feat.npy\" for t in val_idx  ]\n",
    "\n",
    "        train_targ_files = [f\"{targloc}/t{t}_targ.npy\" for t in train_idx]\n",
    "        val_targ_files   = [f\"{targloc}/t{t}_targ.npy\" for t in val_idx]\n",
    "    \n",
    "    elif files == 'kedar':\n",
    "        featloc = \"/home/kphadke/hackathon/norm_data_timesteps_feat\"\n",
    "        targloc = \"/home/kphadke/hackathon/norm_data_timesteps_targ\"\n",
    "\n",
    "        train_feat_files = [f\"{featloc}/{t}feat_norm.npy\" for t in train_idx]\n",
    "        val_feat_files   = [f\"{featloc}/{t}feat_norm.npy\" for t in val_idx  ]\n",
    "\n",
    "        train_targ_files = [f\"{targloc}/{t}targ_norm.npy\" for t in train_idx]\n",
    "        val_targ_files   = [f\"{targloc}/{t}targ_norm.npy\" for t in val_idx]\n",
    "\n",
    "    return [np.array(train_feat_files),np.array(train_targ_files)], [np.array(val_feat_files),np.array(val_targ_files)], feat_idx, target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd90887-cc2d-413d-bbd1-425fe7e148d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep_19_kedar_ccn_001,ccn_003,ccn_006_XLONG,XLAT_tabnet.pt\n",
      "ep_19_kedar_D_ALPHA,D_GAMMA,D_ALPHA_CCN,D_GAMMA_CCN_XLONG,XLAT_tabnet.pt\n",
      "ep_19_sunny_CHI,CHI_CCN_XLONG,XLAT_tabnet.pt\n"
     ]
    }
   ],
   "source": [
    "!ls ep_19*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa2dfeeb-ab31-49b2-930a-04f45ab0e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_name = \"ep_17_kedar_ccn_001,ccn_003,ccn_006_XLONG,XLAT_tabnet.pt\"\n",
    "\n",
    "ckpt_name = \"ep_19_kedar_D_ALPHA,D_GAMMA,D_ALPHA_CCN,D_GAMMA_CCN_XLONG,XLAT_tabnet.pt\"\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "folder_name = f'figs_{ckpt_name.replace(\".pt\",\"\")}'\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "    \n",
    "ckpt = torch.load(ckpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce919f2f-989a-48de-b7bb-ce6897f57502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ckpt['model_state_dict']\n",
    "datasource = ckpt['datasource']\n",
    "exclude_cols =  ckpt['exclude_cols']\n",
    "target_cols =  ckpt['target_cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2da285bd-bc7b-452f-95ef-55d68db93be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the idx used in the model\n",
    "featloc = \"/home/kphadke/hackathon/norm_data_timesteps_feat\"\n",
    "targloc = \"/home/kphadke/hackathon/norm_data_timesteps_targ\"\n",
    "\n",
    "featcols = np.load(f\"{featloc}/x_name.npy\")\n",
    "targcols = np.load(f\"{targloc}/y_name.npy\")\n",
    "\n",
    "target_idx = [np.where(targcols == i)[0].item() for i in target_cols ]\n",
    "feat_idx   = [np.where(featcols == i)[0].item() for i in featcols if i not in exclude_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48636bac-9a69-4a2a-b3a6-e62dfbd78418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# THIS IS JUST FOR TESTING!!!!!!!\n",
    "# WILL CHANGE BACK TO 133 later\n",
    "nsnapshots = 133\n",
    "\n",
    "# DONT CHANGE THE SEEEDDDDDD!!!!!\n",
    "np.random.seed(52)\n",
    "full_indx = np.arange(nsnapshots)\n",
    "train_idx, val_idx = train_test_split(full_indx, test_size=0.2, train_size=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c8772b-2fff-48bd-8e02-756af317ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, val_files, feat_idx, target_idx = getting_datapaths(\n",
    "    train_idx, \n",
    "    val_idx, \n",
    "    files=datasource, \n",
    "    exclude_cols = exclude_cols,\n",
    "    target_cols  = target_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8654755a-a2d6-4462-a365-fed30db95160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTING TESTSET DATA!!!!\n",
    "# get the dataset in place, \n",
    "# make sure it has the appropriate normalizations (reading from the )\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "339b2bfc-3e19-4ec9-8c56-da40046eb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kedar\n",
    "if datasource == 'kedar':\n",
    "    test_feats = [f\"/home/kphadke/hackathon/norm_data_timesteps_feat_eval/{i}feat_norm_eval.npy\" for i in range(12)]\n",
    "    test_targs = [f\"/home/kphadke/hackathon/norm_data_timesteps_targ_eval/{i}targ_norm_eval.npy\" for i in range(12)]\n",
    "else:\n",
    "    test_feats = [f\"/home/kwoksun2/hackathon_data/norm_data_val/t{i}_feat.npy\" for i in range(12)]\n",
    "    test_targs = [f\"/home/kwoksun2/hackathon_data/norm_data_val/t{i}_targ.npy\" for i in range(12)]\n",
    "#     raise ValueError\n",
    "    \n",
    "if datasource == \"sunny\":\n",
    "    target_std= np.array(\n",
    "        [1.3428156,\n",
    "        1.0779657,\n",
    "        1.0479535,\n",
    "        0.08097392,\n",
    "        0.10943509 ,\n",
    "        0.20763765 ,\n",
    "        0.2632665 ,\n",
    "        0.07147439,\n",
    "        0.091097355,\n",
    "        1.1029556\n",
    "        ])\n",
    "    \n",
    "    tstd = target_std[target_idx]\n",
    "    \n",
    "elif datasource == \"kedar\":\n",
    "    target_std = np.load(\"/home/kphadke/hackathon/targ_std.npy\").transpose()\n",
    "    tstd = target_std[:,target_idx]\n",
    "    tstd = tstd[:,np.newaxis,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89607641-6ca5-42b0-ae74-31264e34f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [test_feats, test_targs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4fdb11c-25df-4440-a6bc-1c2c2e0603fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_name = f'predictions_{ckpt_name.replace(\".pt\",\"\")}'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bf78722-9d5d-405d-b930-4a906e4b7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prediction dump\n",
    "feat_files, targ_files = test_files\n",
    "# we are selecting only the first validation data\n",
    "for i in range(len(feat_files)):\n",
    "    feat_data = np.load(feat_files[i])\n",
    "    targ_data = np.load(targ_files[i])\n",
    "\n",
    "    if targ_data.ndim == 1:\n",
    "        targ_data = targ_data.reshape(10,-1).transpose()\n",
    "\n",
    "    tds = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(feat_data[:,feat_idx]).float(), \n",
    "        torch.from_numpy(targ_data[:,target_idx]).float()\n",
    "    )\n",
    "    dl = torch.utils.data.DataLoader(tds, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # turn it in to a data loader for accessing\n",
    "    ypred = []\n",
    "    ytruth = []\n",
    "    xfeats = []\n",
    "    with torch.no_grad():\n",
    "        for feat, targ in dl:\n",
    "            ypred.append(model(feat.cuda())[0].cpu().numpy())\n",
    "            ytruth.append(targ.numpy())\n",
    "            xfeats.append(feat.numpy())\n",
    "\n",
    "    ypred = np.vstack(ypred)\n",
    "    ytruth = np.vstack(ytruth)\n",
    "    xfeats = np.vstack(xfeats)\n",
    "    \n",
    "    np.save(f\"{folder_name}/{i}_xfeats.npy\", xfeats)\n",
    "    np.save(f\"{folder_name}/{i}_ypred.npy\", ypred)\n",
    "    np.save(f\"{folder_name}/{i}_ytruth.npy\", ytruth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238615b-a9a3-4620-99bc-60c028acd1f0",
   "metadata": {},
   "source": [
    "# calculate feature importance first!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0b73a00-5dd7-4db5-b8e2-137492157128",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth3d =  ytruth.reshape(39,159,169,-1)\n",
    "pred3d =  ypred.reshape(39,159,169,-1)\n",
    "pctdiff_cube = np.abs(np.exp((truth3d - pred3d)* tstd) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "427298ec-5f2c-408c-a766-6ed45481eb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3428156, 1.0779657, 1.0479535])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "104cb11c-33d9-4d94-b850-02b2179fa863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 0 cube\n",
      "Starting 0 target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2879950/3836714511.py:73: MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax simultaneously is deprecated since 3.3 and will become an error two minor releases later. Please pass vmin/vmax directly to the norm when creating it.\n",
      "  im3 = ax.flat[2].imshow(pctdiff_cube[zslice, :,:,IDX_targ], vmin=1e-2,vmax=1e0,cmap='magma', norm= LogNorm(1e-2,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 1 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 2 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 3 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 4 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 5 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 6 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 7 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 8 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 9 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 10 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n",
      "Starting 11 cube\n",
      "Starting 0 target\n",
      "Starting 1 target\n",
      "Starting 2 target\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap, LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "for i in range(12):\n",
    "    ytruth = np.load(f\"{folder_name}/{i}_ytruth.npy\")\n",
    "    ypred  = np.load(f\"{folder_name}/{i}_ypred.npy\")\n",
    "    xfeats = np.load(f\"{folder_name}/{i}_xfeats.npy\")\n",
    "    truth3d =  ytruth.reshape(39,159,169,-1)\n",
    "    pred3d =  ypred.reshape(39,159,169,-1)\n",
    "    pctdiff_cube = np.abs(np.exp((truth3d - pred3d)* tstd) - 1)\n",
    "    \n",
    "    \n",
    "    clf = TabNetRegressor(\n",
    "    input_dim=len(feat_idx), \n",
    "    output_dim=len(target_idx), \n",
    "    n_d=8, \n",
    "    n_a=8\n",
    "    )\n",
    "\n",
    "    clf._set_network()\n",
    "    clf._update_network_params()\n",
    "    clf.network = model\n",
    "    \n",
    "    idx_important = []\n",
    "    idx_value     = []\n",
    "\n",
    "    for f in np.array_split(xfeats,100):\n",
    "        t1 = time.time()\n",
    "        explain_matrix, masks = clf.explain(f)\n",
    "        norm_mat = explain_matrix/explain_matrix.sum(-1,keepdims=True)\n",
    "        idx_important.append(norm_mat.argmax(axis=1))\n",
    "        idx_value.append(norm_mat[np.arange(len(norm_mat)),norm_mat.argmax(axis=1)])\n",
    "    #     print(time.time()-t1)\n",
    "\n",
    "    imp = np.hstack(idx_important)\n",
    "\n",
    "    uqix,uq_counts = np.unique(imp,return_counts=True)\n",
    "\n",
    "    # select 5 most important predictor\n",
    "    n_most_important = min(8, len(uq_counts))\n",
    "    tmp = np.argsort(uq_counts)[::-1][:n_most_important]\n",
    "\n",
    "    top_imp_idx    = uqix[tmp]\n",
    "    top_imp_counts = uq_counts[tmp]\n",
    "\n",
    "    ordered_imp = np.zeros_like(imp)+n_most_important\n",
    "    for _i, _idx in enumerate(top_imp_idx):\n",
    "        ordered_imp[imp == _idx] = _i\n",
    "        \n",
    "    cube_important = ordered_imp.reshape(39,159,169,-1)\n",
    "    \n",
    "    print(f\"Starting {i} cube\")\n",
    "    for IDX_targ in range(len(target_idx)):\n",
    "        print(f\"Starting {IDX_targ} target\")\n",
    "        for zslice in range(39):\n",
    "            f,ax = plt.subplots(1,4, figsize=(15,5))\n",
    "\n",
    "            td = truth3d[zslice,:,:,0]\n",
    "\n",
    "            im1 = ax.flat[0].imshow(truth3d[zslice, :,:,IDX_targ], vmin=td.min(), vmax=td.max())\n",
    "            im2 = ax.flat[1].imshow(pred3d[zslice, :,:,IDX_targ], vmin=td.min(), vmax=td.max())\n",
    "\n",
    "            divider = make_axes_locatable(ax.flat[0])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cbar = f.colorbar(im1, cax=cax, orientation='vertical')\n",
    "\n",
    "            divider = make_axes_locatable(ax.flat[1])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cbar = f.colorbar(im1, cax=cax, orientation='vertical')\n",
    "\n",
    "            im3 = ax.flat[2].imshow(pctdiff_cube[zslice, :,:,IDX_targ], vmin=1e-2,vmax=1e0,cmap='magma', norm= LogNorm(1e-2,1))\n",
    "            divider = make_axes_locatable(ax.flat[2])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cbar = f.colorbar(im3, cax=cax, orientation='vertical')\n",
    "\n",
    "\n",
    "            lcmap = cm.get_cmap('Pastel1')\n",
    "            cMap = ListedColormap([lcmap(i) for i in range(n_most_important+1)])\n",
    "\n",
    "            heatmap = ax.flat[3].imshow(cube_important[zslice, :,:,0]+0.5, cmap=cMap, vmin=0, vmax=n_most_important+1)\n",
    "\n",
    "            divider = make_axes_locatable(ax.flat[3])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "            cbar = f.colorbar(heatmap, cax=cax, orientation='vertical')\n",
    "            cbar.set_ticks(np.arange(n_most_important+1)+0.5)\n",
    "            cbar.ax.set_yticklabels(list(featcols[feat_idx][top_imp_idx]) + [\"Rest\"])\n",
    "            # cbar.set_label('# of contacts', rotation=270)\n",
    "\n",
    "            ax.flat[2].set_title(\"percentage error\")\n",
    "            ax.flat[3].set_title(f\"zslice = {zslice}; { targcols[target_idx][IDX_targ] }\")\n",
    "\n",
    "            ax.flat[0].set_title('truth')\n",
    "            ax.flat[1].set_title('pred')\n",
    "            ax.flat[0].set_xticks([])\n",
    "            ax.flat[0].set_yticks([])\n",
    "\n",
    "            ax.flat[1].set_xticks([])\n",
    "            ax.flat[1].set_yticks([])\n",
    "            ax.flat[2].set_xticks([])\n",
    "            ax.flat[2].set_yticks([])\n",
    "\n",
    "            ax.flat[3].set_xticks([])\n",
    "            ax.flat[3].set_yticks([])\n",
    "            # plt.colorbar()\n",
    "            plt.savefig(f\"{folder_name}/t{i}_z{zslice}_{targcols[target_idx][IDX_targ]}\")\n",
    "            plt.close(f)\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41f5aa27-8fbb-4fe5-985f-15ee7d245aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ccn_001', 'ccn_003', 'ccn_006', 'CHI', 'CHI_CCN', 'D_ALPHA',\n",
       "       'D_GAMMA', 'D_ALPHA_CCN', 'D_GAMMA_CCN', 'PM25'], dtype='<U11')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5201d5f-09c1-4c2b-8fd9-8e2f237af268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.5.1]",
   "language": "python",
   "name": "conda-env-opence-v1.5.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
