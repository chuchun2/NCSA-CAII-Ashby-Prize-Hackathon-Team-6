{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147fbf80-15ad-4fc0-9e3e-b5d1c0819b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Models.MLP import SimpleMLP, train_step, val_step\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb81ab-0b67-4bd2-adec-3239a97c93ef",
   "metadata": {},
   "source": [
    "# WARNING using 31 for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebe2b85-8f40-4f3f-b357-acd87d0b7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nsnapshots = 133\n",
    "\n",
    "np.random.seed(52)\n",
    "full_indx = np.arange(nsnapshots)\n",
    "train_idx, val_idx = train_test_split(full_indx, test_size=0.2, train_size=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46aeb1e8-fcbf-48bd-90a2-851b2eb2c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21  95  92  52 110  58  44   8  83  35  50  56 124  36  41 128  98 117\n",
      "  14  60  70 102  29  62  53  75 108 118 116  68  57  93  80  37  73  32\n",
      "  77 119  87  48  55  67  28 115 111 125  91 120 106  12  99 121 129 131\n",
      "  10  94 101  17   9  49  30  38   0  26  85  15 130  25   6  82  65 107\n",
      "  59  64  74  84  78  43  34  20 114   7 126  71  22 100  39  63  76 122\n",
      "  79  45  61  42  46  54 112 132  16 113   5  33  97  86  13  11]\n",
      "[ 40  81  90  69  88  19 127  27 123  66 109 103  96  89  51 104   4   3\n",
      "   2  47  31  23  18  24  72   1 105]\n"
     ]
    }
   ],
   "source": [
    "print(train_idx)\n",
    "print(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15b6675-2109-4029-93e3-9618f0ef4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'kedar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6644cc6-03c0-499b-b9d1-67deeaf6c753",
   "metadata": {},
   "source": [
    "# Dataset guider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc21edd-305d-4e77-9ff6-1855071895de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_datapaths(\n",
    "    train_idx,\n",
    "    val_idx,\n",
    "    files='sunny', \n",
    "    target_cols=[\"ccn_001\", \"ccn_003\", \"ccn_006\"],\n",
    "    exclude_cols = [\"XLONG\", \"XLAT\"],\n",
    "):\n",
    "    # getting colname\n",
    "    featloc = \"/home/kphadke/hackathon/norm_data_timesteps_feat\"\n",
    "    targloc = \"/home/kphadke/hackathon/norm_data_timesteps_targ\"\n",
    "\n",
    "    featcols = np.load(f\"{featloc}/x_name.npy\")\n",
    "    targcols = np.load(f\"{targloc}/y_name.npy\")\n",
    "    \n",
    "    target_idx = [np.where(targcols == i)[0].item() for i in target_cols ]\n",
    "    feat_idx   = [np.where(featcols == i)[0].item() for i in featcols if i not in exclude_cols]\n",
    "    \n",
    "    # getting paths\n",
    "    if files == 'sunny':\n",
    "        # my data\n",
    "        featloc = \"/home/kwoksun2/hackathon_data/norm_data\"\n",
    "        targloc = \"/home/kwoksun2/hackathon_data/norm_data\"\n",
    "\n",
    "        train_feat_files = [f\"{featloc}/t{t}_feat.npy\" for t in train_idx]\n",
    "        val_feat_files   = [f\"{featloc}/t{t}_feat.npy\" for t in val_idx  ]\n",
    "\n",
    "        train_targ_files = [f\"{targloc}/t{t}_targ.npy\" for t in train_idx]\n",
    "        val_targ_files   = [f\"{targloc}/t{t}_targ.npy\" for t in val_idx]\n",
    "    \n",
    "    elif files == 'kedar':\n",
    "        featloc = \"/home/kphadke/hackathon/norm_data_timesteps_feat\"\n",
    "        targloc = \"/home/kphadke/hackathon/norm_data_timesteps_targ\"\n",
    "\n",
    "        train_feat_files = [f\"{featloc}/{t}feat_norm.npy\" for t in train_idx]\n",
    "        val_feat_files   = [f\"{featloc}/{t}feat_norm.npy\" for t in val_idx  ]\n",
    "\n",
    "        train_targ_files = [f\"{targloc}/{t}targ_norm.npy\" for t in train_idx]\n",
    "        val_targ_files   = [f\"{targloc}/{t}targ_norm.npy\" for t in val_idx]\n",
    "\n",
    "    return [np.array(train_feat_files),np.array(train_targ_files)], [np.array(val_feat_files),np.array(val_targ_files)], feat_idx, target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac25fe0-6bcd-4e6a-8114-f50daf9b7eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ccn_001', 'ccn_003', 'ccn_006', 'CHI', 'CHI_CCN', 'D_ALPHA',\n",
       "       'D_GAMMA', 'D_ALPHA_CCN', 'D_GAMMA_CCN', 'PM25'], dtype='<U11')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featloc = \"/home/kphadke/hackathon/norm_data_timesteps_feat\"\n",
    "targloc = \"/home/kphadke/hackathon/norm_data_timesteps_targ\"\n",
    "\n",
    "featcols = np.load(f\"{featloc}/x_name.npy\")\n",
    "targcols = np.load(f\"{targloc}/y_name.npy\")\n",
    "targcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97d7240-601e-4a16-9f47-5f2358deaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols=['ccn_001', 'ccn_003', 'ccn_006'] \n",
    "# target_cols=['CHI', 'CHI_CCN'] \n",
    "# target_cols=['D_ALPHA', 'D_GAMMA', 'D_ALPHA_CCN', 'D_GAMMA_CCN',]\n",
    "\n",
    "exclude_cols = [\"XLONG\", \"XLAT\"]\n",
    "train_files, val_files, feat_idx, target_idx = getting_datapaths(\n",
    "    train_idx, \n",
    "    val_idx, \n",
    "    files=data_source,\n",
    "    target_cols=target_cols,\n",
    "    exclude_cols=exclude_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278141d8-c1fb-4a16-b454-56bc63feac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(feat_files, targ_files, feat_idx, target_idx, box_fraction=0.1, shuffle=True):\n",
    "    NBOX = 39 * 159 * 169\n",
    "    \n",
    "    num_samples_per_box = int(NBOX * box_fraction)\n",
    "    \n",
    "    d = []\n",
    "    t = []\n",
    "    for f_fn, t_fn in zip(feat_files, targ_files):\n",
    "        # select a fraction of data randomly\n",
    "        sidx = np.random.randint(0, NBOX, num_samples_per_box)\n",
    "        feats = np.load(f_fn)\n",
    "        targs = np.load(t_fn)\n",
    "        \n",
    "        if targs.ndim == 1:\n",
    "            targs = targs.reshape(10,-1).transpose()\n",
    "\n",
    "        # keep the subset\n",
    "        d.append(feats[sidx][:,feat_idx])\n",
    "        t.append(targs[sidx][:,target_idx])\n",
    "    train_feat, train_targ = np.vstack(d), np.vstack(t)\n",
    "\n",
    "    tds = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(train_feat).float(), \n",
    "        torch.from_numpy(train_targ).float()\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(tds, batch_size=256, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436cfbfb-cbe3-4f96-a84c-847223d2aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_files, train_targ_files = train_files\n",
    "val_feat_files,   val_targ_files   = val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd84fa1-8d7a-4e99-a1f6-0b9b1c55adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleMLP(ninputs=len(feat_idx), nouts=len(target_idx)).cuda()\n",
    "optim = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdca9c2d-de42-4d9e-bd6f-be047cd8547b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/kphadke/hackathon/norm_data_timesteps_feat/21feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/95feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/92feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/52feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/110feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/58feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/44feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/8feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/83feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/35feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/50feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/56feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/124feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/36feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/41feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/128feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/98feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/117feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/14feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/60feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/70feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/102feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/29feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/62feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/53feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/75feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/108feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/118feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/116feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/68feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/57feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/93feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/80feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/37feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/73feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/32feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/77feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/119feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/87feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/48feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/55feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/67feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/28feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/115feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/111feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/125feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/91feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/120feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/106feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/12feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/99feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/121feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/129feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/131feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/10feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/94feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/101feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/17feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/9feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/49feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/30feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/38feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/0feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/26feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/85feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/15feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/130feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/25feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/6feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/82feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/65feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/107feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/59feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/64feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/74feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/84feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/78feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/43feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/34feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/20feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/114feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/7feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/126feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/71feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/22feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/100feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/39feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/63feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/76feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/122feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/79feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/45feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/61feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/42feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/46feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/54feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/112feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/132feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/16feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/113feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/5feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/33feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/97feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/86feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/13feat_norm.npy',\n",
       "       '/home/kphadke/hackathon/norm_data_timesteps_feat/11feat_norm.npy'],\n",
       "      dtype='<U65')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb646e12-f377-4c2b-8266-9892d0d989d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2457/2457 [00:29<00:00, 84.00it/s]\n",
      "100%|██████████| 2047/2047 [00:21<00:00, 93.13it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 90.82it/s]\n",
      "100%|██████████| 2047/2047 [00:21<00:00, 94.87it/s]\n",
      "100%|██████████| 2047/2047 [00:25<00:00, 81.71it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 92.84it/s]\n",
      "100%|██████████| 2047/2047 [00:23<00:00, 86.69it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 92.79it/s]\n",
      "100%|██████████| 2047/2047 [00:23<00:00, 85.58it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 91.44it/s]\n",
      "100%|██████████| 2047/2047 [00:23<00:00, 88.53it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 92.78it/s]\n",
      "100%|██████████| 2047/2047 [00:21<00:00, 93.30it/s]\n",
      "100%|██████████| 2047/2047 [00:25<00:00, 80.72it/s]\n",
      "100%|██████████| 2047/2047 [00:28<00:00, 72.82it/s]\n",
      "100%|██████████| 2047/2047 [00:28<00:00, 71.23it/s]\n",
      "100%|██████████| 2047/2047 [00:29<00:00, 69.15it/s]\n",
      "100%|██████████| 2047/2047 [00:30<00:00, 66.14it/s]\n",
      "100%|██████████| 2047/2047 [00:29<00:00, 69.88it/s]\n",
      "100%|██████████| 2047/2047 [00:31<00:00, 65.33it/s]\n",
      "100%|██████████| 2047/2047 [00:29<00:00, 68.82it/s]\n",
      "100%|██████████| 2457/2457 [00:25<00:00, 96.45it/s] \n",
      "100%|██████████| 2457/2457 [00:23<00:00, 103.54it/s]\n",
      "100%|██████████| 2047/2047 [00:21<00:00, 97.40it/s] \n",
      "100%|██████████| 2047/2047 [00:19<00:00, 106.28it/s]\n",
      "100%|██████████| 2047/2047 [00:20<00:00, 99.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23800760109604194 0.19108818308558795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2457/2457 [00:33<00:00, 73.45it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 91.35it/s]\n",
      "100%|██████████| 2047/2047 [00:26<00:00, 77.21it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 92.95it/s]\n",
      "100%|██████████| 2047/2047 [00:24<00:00, 84.07it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 91.26it/s]\n",
      "100%|██████████| 2047/2047 [00:22<00:00, 92.60it/s]\n",
      " 28%|██▊       | 578/2047 [00:08<00:23, 63.22it/s]"
     ]
    }
   ],
   "source": [
    "nchunks = 20\n",
    "\n",
    "# per chunk 133/20 ~ 6\n",
    "max_grp_size = 5\n",
    "nchunks_train = len(train_feat_files) // max_grp_size\n",
    "nchunks_val   = len(val_feat_files) // max_grp_size\n",
    "\n",
    "idx_shuf = np.arange(len(train_feat_files))\n",
    "\n",
    "train_hist = []\n",
    "val_hist   = []\n",
    "\n",
    "max_epochs = 100\n",
    "for i in range(max_epochs):\n",
    "    np.random.shuffle(idx_shuf)\n",
    "\n",
    "    train_feat_grps= np.array_split(train_feat_files[idx_shuf], nchunks_train)\n",
    "    train_targ_grps= np.array_split(train_targ_files[idx_shuf], nchunks_train)\n",
    "\n",
    "    val_feat_grps= np.array_split(val_feat_files, nchunks_val)\n",
    "    val_targ_grps= np.array_split(val_targ_files, nchunks_val)\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_val_loss   = 0\n",
    "    total_train_time = 0\n",
    "    total_val_time   = 0\n",
    "\n",
    "    for feat_fns, targs_fns in zip(train_feat_grps, train_targ_grps):\n",
    "        tdl = prepare_dataloaders(\n",
    "            feat_fns, \n",
    "            targs_fns, \n",
    "            feat_idx, \n",
    "            target_idx, \n",
    "            shuffle=True\n",
    "        )\n",
    "        train_loss, train_time = train_step(tdl, net, optim)\n",
    "        total_train_loss += train_loss/ len(train_feat_grps)\n",
    "\n",
    "\n",
    "    for feat_fns, targs_fns in zip(val_feat_grps, val_targ_grps):\n",
    "        tdl = prepare_dataloaders(\n",
    "            feat_fns, \n",
    "            targs_fns,\n",
    "            feat_idx, \n",
    "            target_idx, \n",
    "            shuffle=False)\n",
    "        val_loss, val_time = val_step(tdl, net)\n",
    "        total_val_loss += val_loss/ len(val_feat_grps)\n",
    "        \n",
    "    train_hist.append(total_train_loss)\n",
    "    val_hist.append(total_val_loss)\n",
    "    print(total_train_loss, total_val_loss)\n",
    "        \n",
    "    # checkpoint data\n",
    "    checkpoint = {}\n",
    "    checkpoint['model_state_dict'] = net\n",
    "    checkpoint['epoch'] = i\n",
    "    checkpoint['datasource'] = data_source\n",
    "    checkpoint['exclude_cols'] = exclude_cols\n",
    "    checkpoint['target_cols'] = target_cols\n",
    "    checkpoint['total_train_loss'] = total_train_loss\n",
    "    checkpoint['total_val_loss'] = total_val_loss\n",
    "\n",
    "    torch.save(checkpoint, f\"ep_{i}_{data_source}_{','.join(target_cols)}_{','.join(exclude_cols)}_MLP.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf9888-83a5-4df7-8f7f-0dfcc63a6561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.5.1]",
   "language": "python",
   "name": "conda-env-opence-v1.5.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
